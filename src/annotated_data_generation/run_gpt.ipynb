{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(prompt: str) -> str:\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a professional who can annotate corporate esg report.\"}, \n",
    "                {\"role\": \"user\", \"content\":prompt}]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "                model=\"gpt-4-turbo\",\n",
    "                messages=messages,\n",
    "                temperature= 0.7\n",
    "            )\n",
    "\n",
    "    return response.choices[0].message.content, response.usage\n",
    "\n",
    "def create_prompt(statement_list: list) -> str:\n",
    "    '''\n",
    "    takes in a list of sentence and returns two ouptut, whether it belongs to scope3, how vague the statement is\n",
    "    '''\n",
    "    \n",
    "    prompt = '''Below are statements from a corporate esg report.''' \\\n",
    "    ''' Classify whether the below statements pertains to scope3 emission and how vague the statement is.''' \\\n",
    "    ''' For Scope 3, label it Yes or No. For vagueness, score it if its specific, ambiguous or generic relating to ESG and notESG if it doesnt relate to ESG at all.''' \\\n",
    "    ''' Reply only as a valid json array like this [{{\"scope3\":<answer>, 'vague\":<answer>}},..]'''\\\n",
    "    ''' Here is an example Input:[\"These Scope 3 emissions, encompassing a range of activities from the procurement of goods and services to the use of our sold products, represent a significant portion of our overall carbon footprint.\", \"We have successfully reduced our water usage by 20% in the past year across all operational facilities.\"]'''\\\n",
    "    ''' Response : [{{\"scope3\":\"yes\", \"vague\":\"ambiguous\"}}, {{\"scope3\":\"no\", \"vague\":\"specific\"}}] '''\\\n",
    "    ''' Now do it for below array {statement_list} Response:'''\n",
    "    \n",
    "    modified_prompt = prompt.format(statement_list = statement_list)\n",
    "    \n",
    "    return modified_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running file <_io.TextIOWrapper name='reports/NASDAQ_BKNG_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "Already calculated NASDAQ_BKNG_2022_parsed.txt\n",
      "Running file <_io.TextIOWrapper name='reports/NASDAQ_BKNG_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "No of lines 1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [12:03<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98168 83390 14778\n",
      "Running file <_io.TextIOWrapper name='reports/NYSE_DIS_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "No of lines 948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [10:45<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86991 74091 12900\n",
      "Running file <_io.TextIOWrapper name='reports/NYSE_UBER_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "No of lines 1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [14:54<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116396 99844 16552\n",
      "Running file <_io.TextIOWrapper name='reports/NYSE_TTE_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "No of lines 1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [13:36<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103846 88559 15287\n",
      "Running file <_io.TextIOWrapper name='reports/NYSE_MCD_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "No of lines 1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [12:09<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92034 78161 13873\n",
      "Running file <_io.TextIOWrapper name='reports/NYSE_KO_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "No of lines 2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425/425 [24:29<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189360 160958 28402\n",
      "Running file <_io.TextIOWrapper name='reports/NYSE_NKE_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "No of lines 810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [09:26<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70740 59952 10788\n",
      "Running file <_io.TextIOWrapper name='reports/NYSE_XOM_2022_parsed.txt' mode='r' encoding='UTF-8'>\n",
      "No of lines 1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214/214 [11:53<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98772 84368 14404\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "folder_path = '../parsed_docs/'\n",
    "output_folder = '../annotated_docs/'\n",
    "text_batch_size = 5\n",
    "\n",
    "gpt_calculated_files = [file_name for file_name in os.listdir() if 'results.csv' in file_name]\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    print('Running file', file_name)\n",
    "    if file_name.replace('parsed.txt', 'results.csv') in gpt_calculated_files:\n",
    "        print('Already calculated', file_name)\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [line for line in file.readlines() if line != '\\n']\n",
    "    print('No of lines', len(data))\n",
    "    \n",
    "    text_batches = [data[i:i+text_batch_size] for i in range(0, len(data), text_batch_size)]\n",
    "    responses = []\n",
    "    for batch in tqdm(text_batches):\n",
    "        mod_prompt = create_prompt(batch)\n",
    "        responses.append(call_gpt(mod_prompt))\n",
    "\n",
    "    total=0\n",
    "    completion=0\n",
    "    prompt=0\n",
    "    for i in responses:\n",
    "        total += i[1].total_tokens\n",
    "        completion += i[1].completion_tokens\n",
    "        prompt += i[1].prompt_tokens\n",
    "    print(total, prompt, completion)\n",
    "\n",
    "    all_responses = []\n",
    "    for i, j in zip(responses, text_batches):\n",
    "        try:\n",
    "            string = i[0]\n",
    "            parsed_json = json.loads(string)\n",
    "        except:\n",
    "            try:\n",
    "                string = i[0].replace('```json', '').replace('```', '')\n",
    "                parsed_json = json.loads(string)\n",
    "            except:\n",
    "                print('Error in json', i)\n",
    "\n",
    "        # print(len(parsed_json))\n",
    "        if len(parsed_json) != len(j):\n",
    "            raise ValueError('Length not same as batch_size', len(parsed_json), len(j))\n",
    "        all_responses.extend(parsed_json)\n",
    "\n",
    "    final_df = pd.DataFrame([[i,j] for i,j in zip(data, all_responses)], columns=['text', 'gpt_responses'])\n",
    "    final_df['scope3'] = final_df['gpt_responses'].apply(lambda x: x['scope3'])\n",
    "    final_df['vague'] = final_df['gpt_responses'].apply(lambda x: x['vague'])\n",
    "    \n",
    "    output_file_path = os.path.join(output_folder, file_name.replace('parsed.txt', 'baseline.csv'))\n",
    "    final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYSE_DIS_2022_results.csv\n",
      "NYSE_TTE_2022_results.csv\n",
      "NYSE_MCD_2022_results.csv\n",
      "NYSE_XOM_2022_results.csv\n",
      "NASDAQ_BKNG_2022_results.csv\n",
      "NYSE_NKE_2022_results.csv\n",
      "NYSE_UBER_2022_results.csv\n",
      "NYSE_PFE_2022_results.csv\n",
      "NYSE_KO_2022_results.csv\n",
      "NYSE_DE_2022_results.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in os.listdir():\n",
    "    if 'results.csv' not in file:\n",
    "        continue\n",
    "    print(file)\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    df['file_name'] = file\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "dfs = pd.concat(dfs)\n",
    "dfs.to_csv('final_annotated_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
