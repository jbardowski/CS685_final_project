
In this section, we analyze the correlation between the company scores generated by our results and the results of two externally ranked public datasets. 
The idea is to gain further insights into our method, as a high correlation could provide strong external validation to our method.
Given a less than convincing conclusion, we then explore reasons why our model might differ from the public scores.

For this exercise, we found and scraped two datasets; one from Newsweek's latest annual list of "America's Most Responsible Companies", which includes ESG scores for 600 of the largest corporations in the United States 
and can be found here: https://www.newsweek.com/rankings/americas-most-responsible-companies-2024; and the other from Investor Business Daily's (IBD) annual list of "100 Best ESG Companies For 2022", which 
can be found here: https://www.investors.com/news/esg-companies-list-top-100-esg-stocks-2022/.    

Next, we combined the Newsweek and IBD datasets with our own, which required some finesse since company names do not perfectly match. 
To help us, we employed Python's fuzzywuzzy library, matching our company names separately to Newsweek's and IBD's with fuzzy string matching.
We then analyzed either datasets' results for unmatched companies, making manual changes where the need was apparent (e.g., changing UPS on our side to United Parcel Service).

Using Figure 5 and 6 as a barometer, which shows the histogram of fuzzy string matches between our dataset and Newsweek's and IBD's, respectively, we set a minimum match rate of 87% and 91%.
With this, we were able to match 43 companies from our list to Newsweek and 11 companies to IBD.
Interestingly, some notable companies were not included in the public datasets, including such bellweathers as Amazon, Walmart, Tesla, Pepsi, and Nike in Newsweek for example.

With the datasets now joined, we then normalized the total scores from our method, Newsweek's, and IBD's lists.
Finally, we mapped the Pearson correlation and plotted the results against Newsweek in Figure 7 and IBD in Figure 8.


< Figures >


With a correlation of 0.385 with Newsweek's total score, just 0.257 with Newsweek's ESG score, and 0.632 with IBD's ESG score, the reults are effectively meaningless. 
The main questions these results should raise are why do we differ so much from the public datasets, and does this mean our model is useless?  

We answer the second question by exploring the first, and while there is little observed correlation between our model and the public datasets, we conclude that our model is nonetheless informative.  
Specifically, we found three general areas that could easily cause differences between our model's company scores and the public scores.  

- Different scopes: We specifically looked for Scope3 emissions data with our model, whereas the public datasets were more broad, looking at ESG as a whole. And when comparing Newsweek's total score to its "Environmental Concerns" score (i.e., Scope1-3), we observed large differences within the same dataset.
- Different methodology: It's worth noting that the public datasets were not easy to come by, as nearly all are proprietary. Because of this, we were not successful in finding the methodology behind the public score. However, considering for example that our model penalizes on report size (longer reports get more 'points'), and we assign weights to 'generic', 'specific', or 'vague' statements (subjective summaries), we think it's fair to assume that different methodologies are causing big differences between our scores and the public scores.
- Benchmarks differ between each other: We also compared the correlation between Newsweek and IBD, which included 63 matched companies, observing meager 0.099 (using Newsweek's total score) and 0.146 (on Newsweek's ESG score). The differences between the benchmarks are likely driven by our last point on methodology, and it suggests that low correlations do not mean one model works better than the other.  

