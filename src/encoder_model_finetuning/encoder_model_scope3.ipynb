{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope3 Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "model_name = 'intfloat/e5-large-v2'\n",
    "vagueness_class_mapping = {\"specific\":1, \"ambiguous\":2, \"generic\":3, \"notESG\":0 }\n",
    "scope3_class_mapping = {\"yes\":1, \"no\":0}\n",
    "train_file_path = 'train_data.csv'\n",
    "test_file_path = 'test_data.csv'\n",
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 8\n",
    "lr = 1e-5\n",
    "epochs = 30\n",
    "train_test_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_format(sentences, max_sentence_length=200):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True, use_fast=False)\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sentence,\n",
    "                            add_special_tokens = True,\n",
    "                            max_length = max_sentence_length,\n",
    "                            padding = 'max_length',\n",
    "                            truncation = True,\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt',\n",
    "                        )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, df, scope3_class_mapping, vagueness_class_mapping, augment=False):\n",
    "        self.df = df\n",
    "        self.texts = self.df['text'].tolist()\n",
    "        self.scope3 = self.df['scope3'].apply(lambda x: scope3_class_mapping[x]).tolist()\n",
    "        self.vagueness = self.df['vague'].apply(lambda x: vagueness_class_mapping[x]).tolist()\n",
    "\n",
    "        if augment:\n",
    "\n",
    "            batch_size = 16\n",
    "            \n",
    "            aug1 = naw.BackTranslationAug(from_model_name='facebook/wmt19-en-de', to_model_name='facebook/wmt19-de-en', device='cuda', batch_size=batch_size, verbose=True)\n",
    "            aug2 = naw.SynonymAug(aug_src='wordnet')\n",
    "            \n",
    "            aug_text1 = aug1.augment(self.texts)\n",
    "            aug_text2 = aug2.augment(self.texts)\n",
    "\n",
    "            self.texts = np.concatenate([self.texts, aug_text1, aug_text2])\n",
    "            self.scope3 = np.concatenate([self.scope3, self.scope3, self.scope3])\n",
    "            # self.vagueness = np.concatenate([self.vagueness, self.vagueness, self.vagueness])\n",
    "\n",
    "\n",
    "        self.input_ids, self.attention_masks = tokenize_and_format(self.texts)\n",
    "        self.scope3 = torch.tensor(self.scope3)\n",
    "        # self.vagueness = torch.tensor(self.vagueness)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_masks[idx], self.scope3[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file_path)\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "train_len = len(train_df)\n",
    "test_len = len(test_df)\n",
    "\n",
    "num_val = int(train_test_split * train_len)\n",
    "\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "validation_df = train_df.iloc[:num_val]\n",
    "train_df = train_df.iloc[num_val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df), len(validation_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set statistics\")\n",
    "print(train_df['scope3'].value_counts())\n",
    "# print(train_df['vague'].value_counts())\n",
    "\n",
    "print(\"\\nValidation set statistics\")\n",
    "print(validation_df['scope3'].value_counts())\n",
    "# print(validation_df['vague'].value_counts())\n",
    "\n",
    "print(\"\\nTest set statistics\")\n",
    "print(test_df['scope3'].value_counts())\n",
    "# print(test_df['vague'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiTaskDataset(train_df, scope3_class_mapping, vagueness_class_mapping, augment=False)\n",
    "valid_dataset = MultiTaskDataset(validation_df, scope3_class_mapping, vagueness_class_mapping)\n",
    "test_dataset = MultiTaskDataset(test_df, scope3_class_mapping, vagueness_class_mapping)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'intfloat/e5-large-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTMultiTask(torch.nn.Module):\n",
    "    def __init__(self, encoder_model='bert-base-uncased'):\n",
    "        super(BERTMultiTask, self).__init__()\n",
    "\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_model)\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        self.linear1 = torch.nn.Linear(hidden_size, 256)\n",
    "        self.linear2 = torch.nn.Linear(256, 256)\n",
    "        self.scope3_out = torch.nn.Linear(256, 2)\n",
    "        # self.vagueness_out = torch.nn.Linear(256, 4)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, mask):\n",
    "        outputs = self.encoder(input_ids, attention_mask=mask)\n",
    "\n",
    "        linear1_out = self.relu(self.linear1(outputs.last_hidden_state[:,0,:]))\n",
    "        linear2_out = self.relu(self.linear2(linear1_out))\n",
    "        scope3_out = self.scope3_out(linear2_out)\n",
    "        # vagueness_out = self.vagueness_out(linear1_out)\n",
    "        return scope3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTMultiTask(encoder_model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_size = sum([p.nelement() for p in model.parameters()])\n",
    "print(f\"Model parameters: {model_param_size/1e6}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params = list(model.encoder.named_parameters())\n",
    "new_layer_params = list(model.scope3_out.named_parameters()) + list(model.linear1.named_parameters()) + list(model.linear2.named_parameters())\n",
    "no_decay = {'bias', 'LayerNorm.weight'}\n",
    "\n",
    "base_learning_rate = 1e-5\n",
    "new_learning_rate = 1e-4\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in encoder_params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01, 'lr': base_learning_rate},\n",
    "    {'params': [p for n, p in encoder_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0, 'lr': base_learning_rate},\n",
    "    {'params': [p for n, p in new_layer_params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01, 'lr': new_learning_rate},\n",
    "    {'params': [p for n, p in new_layer_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0, 'lr': new_learning_rate}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=base_learning_rate, eps=1e-8)\n",
    "# optimizer = AdamW(model.parameters(), lr=base_learning_rate, eps=1e-8)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.33, patience=2, verbose=True)\n",
    "ce_loss = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.encoder.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true, class_mapping):\n",
    "    \n",
    "    y_pred_class = torch.argmax(y_pred, dim=-1)\n",
    "    reverse_class_mapping = {v:k for k,v in class_mapping.items()}\n",
    "\n",
    "    metrics = []\n",
    "    for i in reverse_class_mapping:\n",
    "\n",
    "        true_positives = torch.sum((y_pred_class == i) & (y_true == i)).item()\n",
    "        true_negatives = torch.sum((y_pred_class != i) & (y_true != i)).item()\n",
    "        false_positives = torch.sum((y_pred_class == i) & (y_true != i)).item()\n",
    "        false_negatives = torch.sum((y_pred_class != i) & (y_true == i)).item()\n",
    "\n",
    "        accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "        precision = true_positives / (true_positives + false_positives) if true_positives + false_positives != 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives != 0 else 0\n",
    "\n",
    "        class_name = reverse_class_mapping[i]\n",
    "        metrics.append(f'Accuracy_{class_name}: {accuracy:.4f} | Precision_{class_name}: {precision:.4f} | Recall_{class_name}: {recall:.4f}|')\n",
    "\n",
    "    metrics = \" \".join(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = 10000\n",
    "best_val_epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # running_vagueness_tensor = torch.tensor([]).to(device)\n",
    "    running_scope3_tensor = torch.tensor([]).to(device)\n",
    "    # running_vagueness_pred_tensor = torch.tensor([]).to(device)\n",
    "    running_scope3_pred_tensor = torch.tensor([]).to(device)\n",
    "\n",
    "    num_batches = len(train_dataloader)\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        \n",
    "        input_id_tensors = data[0].to(device)\n",
    "        input_mask_tensors = data[1].to(device)\n",
    "        # vagueness_tensors = data[2].to(device)\n",
    "        scope3_tensors = data[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(input_id_tensors, mask=input_mask_tensors)\n",
    "\n",
    "        # vagueness_loss = ce_loss(outputs[0], vagueness_tensors)\n",
    "        scope3_loss = ce_loss(outputs, scope3_tensors)\n",
    "\n",
    "        final_loss = scope3_loss\n",
    "\n",
    "        total_train_loss += final_loss.item()\n",
    "\n",
    "        final_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # running_vagueness_tensor = torch.cat([running_vagueness_tensor, vagueness_tensors])\n",
    "        running_scope3_tensor = torch.cat([running_scope3_tensor, scope3_tensors])\n",
    "        # running_vagueness_pred_tensor = torch.cat([running_vagueness_pred_tensor, outputs[0]])\n",
    "        running_scope3_pred_tensor = torch.cat([running_scope3_pred_tensor, outputs])\n",
    "\n",
    "        # vagueness_metrics = calculate_metrics(running_vagueness_pred_tensor, running_vagueness_tensor, vagueness_class_mapping)\n",
    "        scope3_metrics = calculate_metrics(running_scope3_pred_tensor, running_scope3_tensor, scope3_class_mapping)\n",
    "\n",
    "        average_train_loss = total_train_loss / (i+1)\n",
    "    \n",
    "        print(f'\\rBatch [{i+1}/{num_batches}], Average Train Loss: {average_train_loss:.4f}', scope3_metrics, end='')\n",
    "\n",
    "    print(\"\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        total_valid_loss = 0\n",
    "        # running_vagueness_tensor = torch.tensor([]).to(device)\n",
    "        running_scope3_tensor = torch.tensor([]).to(device)\n",
    "        # running_vagueness_pred_tensor = torch.tensor([]).to(device)\n",
    "        running_scope3_pred_tensor = torch.tensor([]).to(device)\n",
    "\n",
    "        for data in valid_dataloader:\n",
    "            \n",
    "            input_id_tensors = data[0].to(device)\n",
    "            input_mask_tensors = data[1].to(device)\n",
    "            # vagueness_tensors = data[2].to(device)\n",
    "            scope3_tensors = data[2].to(device)\n",
    "\n",
    "            outputs = model(input_id_tensors, mask=input_mask_tensors)\n",
    "\n",
    "            # vagueness_loss = ce_loss(outputs[0], vagueness_tensors)\n",
    "            scope3_loss = ce_loss(outputs, scope3_tensors)\n",
    "\n",
    "            final_loss = scope3_loss\n",
    "            \n",
    "            total_valid_loss += final_loss.item()\n",
    "\n",
    "            # running_vagueness_tensor = torch.cat([running_vagueness_tensor, vagueness_tensors])\n",
    "            running_scope3_tensor = torch.cat([running_scope3_tensor, scope3_tensors])\n",
    "            # running_vagueness_pred_tensor = torch.cat([running_vagueness_pred_tensor, outputs[0]])\n",
    "            running_scope3_pred_tensor = torch.cat([running_scope3_pred_tensor, outputs])\n",
    "        \n",
    "        average_valid_loss = total_valid_loss / len(valid_dataloader)\n",
    "        scheduler.step(average_valid_loss)\n",
    "\n",
    "        if average_valid_loss < best_val_loss:\n",
    "            best_val_loss = average_valid_loss\n",
    "            best_val_epoch = epoch_i\n",
    "            torch.save(model.state_dict(), 'best_model_scope3.pth')\n",
    "\n",
    "        # vagueness_metrics = calculate_metrics(running_vagueness_pred_tensor, running_vagueness_tensor, vagueness_class_mapping)\n",
    "        scope3_metrics = calculate_metrics(running_scope3_pred_tensor, running_scope3_tensor, scope3_class_mapping)\n",
    "\n",
    "        \n",
    "\n",
    "        print(f'Avg Validation Loss: {average_valid_loss:.4f} | Best Validation Loss: {best_val_loss:.4f} | Best Epoch: {best_val_epoch}',scope3_metrics)\n",
    "        \n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.texts = self.df['text'].values\n",
    "\n",
    "        self.input_ids, self.attention_masks = tokenize_and_format(self.texts)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = BERTMultiTask(encoder_model=model_name)\n",
    "model.load_state_dict(torch.load('best_model_scope3.pth'))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "inference_dataset = MultiTaskDataset(test_df, scope3_class_mapping, vagueness_class_mapping, augment=False)\n",
    "inference_dataloader = DataLoader(inference_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# inference\n",
    "vagueness_inference = []\n",
    "scope3_inference = []\n",
    "\n",
    "reverse_vagueness_class_mapping = {v:k for k,v in vagueness_class_mapping.items()}\n",
    "reverse_scope3_class_mapping = {v:k for k,v in scope3_class_mapping.items()}\n",
    "with torch.no_grad():\n",
    "    # running_vagueness_tensor = torch.tensor([]).to(device)\n",
    "    running_scope3_tensor = torch.tensor([]).to(device)\n",
    "    # running_vagueness_pred_tensor = torch.tensor([]).to(device)\n",
    "    running_scope3_pred_tensor = torch.tensor([]).to(device)\n",
    "    for data in inference_dataloader:\n",
    "        \n",
    "        input_id_tensors = data[0].to(device)\n",
    "        input_mask_tensors = data[1].to(device)\n",
    "        # vagueness_tensors = data[2].to(device)\n",
    "        scope3_tensors = data[2].to(device)\n",
    "\n",
    "        outputs = model(input_id_tensors, mask=input_mask_tensors)\n",
    "\n",
    "        # running_vagueness_tensor = torch.cat([running_vagueness_tensor, vagueness_tensors])\n",
    "        running_scope3_tensor = torch.cat([running_scope3_tensor, scope3_tensors])\n",
    "        # running_vagueness_pred_tensor = torch.cat([running_vagueness_pred_tensor, outputs[0]])\n",
    "        running_scope3_pred_tensor = torch.cat([running_scope3_pred_tensor, outputs])\n",
    "\n",
    "        # vagueness_pred = torch.argmax(outputs[0], dim=-1).to('cpu').tolist()\n",
    "        scope3_pred = torch.argmax(outputs, dim=-1).to('cpu').tolist()\n",
    "\n",
    "        # vagueness_inference.extend([reverse_vagueness_class_mapping[x] for x in vagueness_pred])\n",
    "        scope3_inference.extend([reverse_scope3_class_mapping[x] for x in scope3_pred])\n",
    "\n",
    "    # vagueness_metrics = calculate_metrics(running_vagueness_pred_tensor, running_vagueness_tensor, vagueness_class_mapping)\n",
    "    scope3_metrics = calculate_metrics(running_scope3_pred_tensor, running_scope3_tensor, scope3_class_mapping)\n",
    "\n",
    "# test_df['vagueness_pred'] = vagueness_inference\n",
    "test_df['scope3_pred'] = scope3_inference\n",
    "# print(vagueness_metrics)\n",
    "print(scope3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
